# ğŸ”¥ EXAM PRIORITY TOPICS - THEORY EXAM GUIDE

## âš ï¸ Teacher's High Priority List - EXPLAINED FOR BEGINNERS

**DON'T PANIC!** This guide explains everything from scratch. Read slowly and understand the concepts.

---

## ğŸ“– HOW TO USE THIS GUIDE (THEORY EXAM STRATEGY)

For theory exams, focus on:
1. **Definitions** - What is it?
2. **Purpose** - Why do we use it?
3. **Steps** - How does it work?
4. **Example** - Small walkthrough
5. **Complexity** - Time/Space (Big O notation)
6. **When to use** - Applications

You DON'T need to write actual code, just understand the logic!

---

## ğŸ“Š **GRAPH ALGORITHMS** â­â­â­â­â­

### 1. KRUSKAL'S ALGORITHM (Minimum Spanning Tree)

**ğŸ“– WHAT IS IT?**
Kruskal's algorithm finds the cheapest way to connect all vertices (cities/nodes) in a graph using edges (roads) without forming cycles (loops).

**ğŸ¯ WHY USE IT?**
- Design minimum cost road/cable networks
- Connect all cities with minimum total distance
- Network design problems

**ğŸ“ DEFINITION FOR EXAM:**
"Kruskal's algorithm is a greedy algorithm that finds a Minimum Spanning Tree (MST) for a weighted undirected graph by selecting edges in increasing order of weight, avoiding cycles using Union-Find data structure."

**ğŸ”¢ HOW IT WORKS (Simple Steps):**
1. **Sort all edges** by weight (smallest to largest)
2. **Pick smallest edge** that doesn't create a cycle
3. **Repeat** until you have (V-1) edges (V = number of vertices)
4. **Done!** You have the MST

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Graph with 4 cities (0,1,2,3):

Roads with costs:
- Road between city 1 and 2: cost 1 â‚¹
- Road between city 0 and 1: cost 2 â‚¹
- Road between city 0 and 2: cost 3 â‚¹
- Road between city 1 and 3: cost 4 â‚¹
- Road between city 2 and 3: cost 5 â‚¹

VISUAL DIAGRAM:

Initial Graph (all edges):
        (2)
    0 --------- 1
    |     (1)  /|
 (3)|        /  |(4)
    |      /    |
    |    /      |
    2 --------- 3
        (5)

Step-by-Step MST Construction:

Step 1: Pick edge (1-2, cost=1) âœ“
    0           1
                |
             (1)|
                |
                2           3

Step 2: Pick edge (0-1, cost=2) âœ“
        (2)
    0 --------- 1
                |
             (1)|
                |
                2           3

Step 3: Skip edge (0-2, cost=3) âœ—
    (Would create cycle: 0-1-2-0)
    Already connected via 0â†’1â†’2

Step 4: Pick edge (1-3, cost=4) âœ“
        (2)
    0 --------- 1
                |\
             (1)| \(4)
                |  \
                2   3

FINAL MST:
        (2)
    0 --------- 1
                |\
             (1)| \(4)
                |  \
                2   3

RESULT: 
- Edges selected: (1-2), (0-1), (1-3)
- Total cost = 1 + 2 + 4 = 7 â‚¹
- All cities connected with minimum cost! âœ“
- Number of edges = 3 (which is V-1 = 4-1) âœ“
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(E log E) - mainly due to sorting edges
- **Space**: O(V) - for storing parent/rank arrays

**âœï¸ FOR THEORY EXAM WRITE:**
- "Kruskal's uses **greedy approach** on edges"
- "Uses **Union-Find** to detect cycles"
- "Produces MST with (V-1) edges"
- "Better for **sparse graphs** (fewer edges)"

**ğŸ†š COMPARISON:**
Kruskal vs Prim:
- Kruskal: Works on edges, good for sparse graphs
- Prim: Works on vertices, good for dense graphs

### 2. DIJKSTRA'S ALGORITHM (Shortest Path)

**ğŸ“– WHAT IS IT?**
Dijkstra's algorithm finds the shortest path from a starting point (source) to all other points in a graph.

**ğŸ¯ WHY USE IT?**
- GPS navigation (find shortest route)
- Network routing (find fastest data path)
- Game AI (find shortest path for character)

**ğŸ“ DEFINITION FOR EXAM:**
"Dijkstra's algorithm is a greedy algorithm that finds the shortest path from a source vertex to all other vertices in a weighted graph with non-negative edge weights, using a priority queue (min-heap)."

**ğŸ”¢ HOW IT WORKS (Simple Steps):**
1. **Start** at source, mark distance as 0
2. **All other** vertices: mark distance as âˆ (infinity)
3. **Pick vertex** with smallest distance (not yet visited)
4. **Update** distances to its neighbors if shorter path found
5. **Repeat** until all vertices visited

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Cities: Delhi(0), Mumbai(1), Bangalore(2), Chennai(3)
Find shortest distance from Delhi to all cities

Connections:
Delhi â†’ Mumbai: 4 km
Mumbai â†’ Bangalore: 2 km
Bangalore â†’ Chennai: 3 km
Delhi â†’ Bangalore: 6 km (direct)

SOLUTION:
Initial: [0, âˆ, âˆ, âˆ]
After visiting Delhi: [0, 4, 6, âˆ]
After visiting Mumbai: [0, 4, 6, 9]
After visiting Bangalore: [0, 4, 6, 9]

RESULT:
Delhi â†’ Mumbai: 4 km
Delhi â†’ Bangalore: 6 km
Delhi â†’ Chennai: 9 km (via Mumbai, Bangalore)
```

**â±ï¸ COMPLEXITY:**
- **Time**: O((V+E) log V) with min-heap
- **Space**: O(V) for distance array

**âš ï¸ IMPORTANT LIMITATION:**
- **ONLY works** with NON-NEGATIVE weights!
- If graph has negative weights, use Bellman-Ford instead

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **greedy approach** - always picks closest unvisited vertex"
- "Uses **min-heap/priority queue** for efficiency"
- "Cannot handle **negative weights**"
- "Finds shortest path from **one source** to all vertices"

**ğŸ†š WHEN TO USE WHAT:**
- **Dijkstra**: Non-negative weights, faster â†’ USE THIS!
- **Bellman-Ford**: Any weights (including negative), slower
- **Floyd-Warshall**: All pairs shortest paths

---

## ğŸ” **RECURSION** â­â­â­â­â­

**ğŸ“– WHAT IS RECURSION?**
Recursion means a function calling itself to solve a smaller version of the same problem.

**Think of it like:** Russian dolls - each doll contains a smaller doll inside!

### 1. FIBONACCI SEQUENCE

**ğŸ“– WHAT IS IT?**
A series of numbers where each number is the sum of the previous two:
0, 1, 1, 2, 3, 5, 8, 13, 21...

**ğŸ“ DEFINITION FOR EXAM:**
"Fibonacci is a recursive sequence where F(n) = F(n-1) + F(n-2), with base cases F(0)=0 and F(1)=1."

**ğŸ”¢ HOW IT WORKS:**
```
Fibonacci(n):
    If n = 0: return 0  â† BASE CASE
    If n = 1: return 1  â† BASE CASE
    Otherwise: return Fibonacci(n-1) + Fibonacci(n-2)  â† RECURSIVE CALL
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Find Fibonacci(5):

F(5) = F(4) + F(3)
F(4) = F(3) + F(2)
F(3) = F(2) + F(1) = 2 + 1 = 3
F(2) = F(1) + F(0) = 1 + 0 = 1

So: F(5) = 5

Sequence: 0, 1, 1, 2, 3, 5
          â†‘  â†‘  â†‘  â†‘  â†‘  â†‘
         F0 F1 F2 F3 F4 F5
```

**â±ï¸ COMPLEXITY:**
- **Naive Recursion**: O(2^n) - Very slow! (exponential)
- **With DP (Dynamic Programming)**: O(n) - Much faster!

**âœï¸ FOR THEORY EXAM WRITE:**
- "Shows concept of **overlapping subproblems**"
- "Base cases are F(0)=0 and F(1)=1"
- "Can be optimized using Dynamic Programming"
- "Real-world uses: Nature patterns, algorithm analysis"

### 2. TOWER OF HANOI

**ğŸ“– WHAT IS IT?**
A puzzle with 3 pegs (rods) and n disks of different sizes. Move all disks from first peg to last peg.

**ğŸ¯ RULES:**
1. Move only ONE disk at a time
2. Larger disk can NEVER be on top of smaller disk
3. Use 3 pegs: Source, Auxiliary (helper), Destination

**ğŸ“ DEFINITION FOR EXAM:**
"Tower of Hanoi is a classic recursive problem where n disks must be moved from source to destination using an auxiliary peg, following the rule that no larger disk can be placed on a smaller disk."

**ğŸ”¢ HOW IT WORKS (3 Steps):**
```
To move n disks from A to C using B:

1. Move (n-1) disks from A to B (using C as helper)
2. Move largest disk from A to C
3. Move (n-1) disks from B to C (using A as helper)
```

**ğŸ‘‰ SIMPLE EXAMPLE (2 disks):**
```
Initial: A has disks 1,2 (small=1, large=2)
Goal: Move all to C

Step 1: Move disk 1 from A to B
   A: [2]    B: [1]    C: []

Step 2: Move disk 2 from A to C
   A: []     B: [1]    C: [2]

Step 3: Move disk 1 from B to C
   A: []     B: []     C: [2,1]

DONE! Total moves = 3 (which is 2^2 - 1)
```

**ğŸ“ FORMULA:**
Total moves for n disks = **2^n - 1**
- 1 disk: 1 move
- 2 disks: 3 moves
- 3 disks: 7 moves
- 4 disks: 15 moves

**â±ï¸ COMPLEXITY:**
- **Time**: O(2^n) - exponential
- **Moves needed**: 2^n - 1

**âœï¸ FOR THEORY EXAM WRITE:**
- "Classic example of **divide and conquer**"
- "Recurrence: T(n) = 2T(n-1) + 1"
- "Minimum moves = 2^n - 1"
- "Shows exponential time complexity"

### 3. FACTORIAL

**ğŸ“– WHAT IS IT?**
Factorial of n (written as n!) means multiply all numbers from 1 to n.

**ğŸ“ DEFINITION FOR EXAM:**
"Factorial of n (n!) is the product of all positive integers from 1 to n. Recursively: n! = n Ã— (n-1)!"

**ğŸ”¢ HOW IT WORKS:**
```
Factorial(n):
    If n = 0 or n = 1: return 1  â† BASE CASE
    Otherwise: return n Ã— Factorial(n-1)  â† RECURSIVE CALL
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Find 5!:

5! = 5 Ã— 4!
4! = 4 Ã— 3!
3! = 3 Ã— 2!
2! = 2 Ã— 1!
1! = 1  â† BASE CASE

Backtrack:
2! = 2 Ã— 1 = 2
3! = 3 Ã— 2 = 6
4! = 4 Ã— 6 = 24
5! = 5 Ã— 24 = 120

Answer: 5! = 120
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n) - calls n times
- **Space**: O(n) - recursive stack

**âœï¸ FOR THEORY EXAM WRITE:**
- "Simple example of **linear recursion**"
- "Base case: 0! = 1 and 1! = 1"
- "Used in permutations and combinations"
- "Can be easily converted to iterative (loop)"

### 4. GCD (Greatest Common Divisor)

**ğŸ“– WHAT IS IT?**
GCD is the largest number that divides both given numbers evenly.

**ğŸ“ DEFINITION FOR EXAM:**
"GCD of two numbers is the largest positive integer that divides both numbers without leaving a remainder. Uses Euclidean algorithm: GCD(a,b) = GCD(b, a mod b)."

**ğŸ”¢ HOW IT WORKS (Euclidean Method):**
```
GCD(a, b):
    If b = 0: return a  â† BASE CASE
    Otherwise: return GCD(b, a % b)  â† RECURSIVE CALL
    
% means remainder (modulo)
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Find GCD(48, 18):

Step 1: GCD(48, 18)
        48 Ã· 18 = 2 remainder 12
        So: GCD(18, 12)

Step 2: GCD(18, 12)
        18 Ã· 12 = 1 remainder 6
        So: GCD(12, 6)

Step 3: GCD(12, 6)
        12 Ã· 6 = 2 remainder 0
        So: GCD(6, 0)

Step 4: GCD(6, 0)
        b = 0, so return 6  â† ANSWER!

GCD(48, 18) = 6
```

**âœ… VERIFY:** 48Ã·6=8, 18Ã·6=3 âœ“

**â±ï¸ COMPLEXITY:**
- **Time**: O(log(min(a,b))) - Very fast!
- **Space**: O(log(min(a,b)))

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **Euclidean algorithm** - ancient and efficient"
- "Repeatedly divides until remainder = 0"
- "Logarithmic time complexity"
- "Used in: simplifying fractions, cryptography"

### 5. LCM (Least Common Multiple)

**ğŸ“– WHAT IS IT?**
LCM is the smallest number that is divisible by both given numbers.

**ğŸ“ DEFINITION FOR EXAM:**
"LCM of two numbers is the smallest positive integer that is a multiple of both numbers. Formula: LCM(a,b) = (a Ã— b) / GCD(a,b)."

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Find LCM(12, 18):

Step 1: Find GCD(12, 18) = 6
Step 2: Apply formula:
        LCM = (12 Ã— 18) / 6
        LCM = 216 / 6
        LCM = 36

âœ… Verify: 36Ã·12=3, 36Ã·18=2 âœ“
```

**ğŸ“ IMPORTANT FORMULA:**
**LCM(a,b) Ã— GCD(a,b) = a Ã— b**

**â±ï¸ COMPLEXITY:**
- **Time**: O(log(min(a,b))) - same as GCD

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses GCD for calculation"
- "Formula: LCM = (aÃ—b) / GCD(a,b)"
- "Used in: finding common denominators"

---

### 6. SUM (Recursive)

**ğŸ“– WHAT IS IT?**
Adding numbers recursively - either array elements or digits of a number.

**ğŸ“ DEFINITION FOR EXAM:**
"Recursive sum breaks down the addition problem into smaller subproblems until reaching a base case."

**ğŸ”¢ TWO TYPES:**

**A) Sum of Array Elements:**
```
Sum([5, 3, 8, 2]):
    = 5 + Sum([3, 8, 2])
    = 5 + 3 + Sum([8, 2])
    = 5 + 3 + 8 + Sum([2])
    = 5 + 3 + 8 + 2 + Sum([]) â† BASE CASE (empty = 0)
    = 18
```

**B) Sum of Digits:**
```
Find sum of digits of 1234:

1234 â†’ last digit = 4, remaining = 123
4 + SumDigits(123)

123 â†’ last digit = 3, remaining = 12
4 + 3 + SumDigits(12)

12 â†’ last digit = 2, remaining = 1
4 + 3 + 2 + SumDigits(1)

1 â†’ last digit = 1, remaining = 0
4 + 3 + 2 + 1 + SumDigits(0) â† BASE CASE

Answer: 10
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n) where n = array size or number of digits
- **Space**: O(n) for recursive stack

**âœï¸ FOR THEORY EXAM WRITE:**
- "Example of **linear recursion**"
- "Base case: empty array returns 0, or number = 0"
- "Simple but demonstrates recursion concept well"

---

## ğŸ¯ **GREEDY ALGORITHMS** â­â­â­â­

**ğŸ“– WHAT ARE GREEDY ALGORITHMS?**
Greedy algorithms make the **locally optimal choice** at each step, hoping to find a global optimum.

**Think of it like:** Always taking the best option RIGHT NOW, without looking ahead!

### 1. ACTIVITY SELECTION PROBLEM

**ğŸ“– WHAT IS IT?**
Given activities with start and end times, select maximum number of activities that don't overlap.

**ğŸ¯ REAL-WORLD USE:**
- Meeting room scheduling
- Class timetable planning
- TV show scheduling

**ğŸ“ DEFINITION FOR EXAM:**
"Activity Selection is a greedy algorithm that selects maximum number of non-overlapping activities by always choosing the activity that finishes earliest."

**ğŸ”¢ HOW IT WORKS:**
```
1. SORT all activities by finish time (earliest first)
2. SELECT first activity
3. For remaining activities:
   - If start time â‰¥ previous finish time â†’ SELECT it
   - Otherwise â†’ SKIP it
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Activities (start, finish):
A1: (1, 3)
A2: (2, 5)  
A3: (4, 7)
A4: (1, 8)
A5: (5, 9)
A6: (8, 10)

After sorting by finish time (already sorted above):

Step 1: Select A1 (1,3) âœ“
Step 2: A2 starts at 2, but A1 finishes at 3 â†’ SKIP
Step 3: A3 starts at 4 â‰¥ 3 â†’ SELECT âœ“
Step 4: A4 overlaps â†’ SKIP
Step 5: A5 starts at 5 < 7 â†’ SKIP
Step 6: A6 starts at 8 â‰¥ 7 â†’ SELECT âœ“

ANSWER: 3 activities (A1, A3, A6)
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n log n) - due to sorting
- **Space**: O(1)

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **greedy strategy** - earliest finish time first"
- "Guarantees optimal solution"
- "Can prove correctness using **exchange argument**"

---

### 2. FRACTIONAL KNAPSACK

**ğŸ“– WHAT IS IT?**
Given items with weights and values, fill a bag of limited capacity to maximize total value. Can take fractions of items.

**ğŸ¯ REAL-WORLD USE:**
- Loading cargo in truck (can break items)
- Resource allocation
- Portfolio management

**ğŸ“ DEFINITION FOR EXAM:**
"Fractional Knapsack uses greedy approach to maximize value by selecting items in decreasing order of value-to-weight ratio, taking fractions if needed."

**ğŸ”¢ HOW IT WORKS:**
```
1. Calculate VALUE/WEIGHT ratio for each item
2. SORT items by ratio (highest first)
3. Keep ADDING items until bag is full
4. If item doesn't fit completely, take FRACTION
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Bag capacity: 50 kg

Items:
Item 1: Weight=10kg, Value=â‚¹60  â†’ Ratio=6
Item 2: Weight=20kg, Value=â‚¹100 â†’ Ratio=5
Item 3: Weight=30kg, Value=â‚¹120 â†’ Ratio=4

Sorted by ratio: Item1, Item2, Item3

Step 1: Take Item1 (10kg) â†’ Remaining: 40kg, Value: â‚¹60
Step 2: Take Item2 (20kg) â†’ Remaining: 20kg, Value: â‚¹160
Step 3: Take 20kg of Item3 (20/30 = 2/3)
        â†’ Value = 2/3 Ã— â‚¹120 = â‚¹80

TOTAL VALUE: â‚¹60 + â‚¹100 + â‚¹80 = â‚¹240
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n log n) - sorting
- **Space**: O(1)

**âš ï¸ IMPORTANT:**
- **FRACTIONAL** Knapsack â†’ Greedy WORKS âœ“
- **0/1** Knapsack â†’ Greedy FAILS âœ— (use DP instead!)

**âœï¸ FOR THEORY EXAM WRITE:**
- "Greedy strategy: **highest value/weight ratio first**"
- "Works only for **fractional** version"
- "For 0/1 Knapsack, must use Dynamic Programming"

---

### 3. COIN CHANGE (Greedy Approach)

**ğŸ“– WHAT IS IT?**
Make change for an amount using minimum number of coins.

**ğŸ“ DEFINITION FOR EXAM:**
"Coin Change greedy approach selects largest denomination coins first to minimize coin count. Works for standard denominations but NOT always optimal for arbitrary coin sets."

**ğŸ”¢ HOW IT WORKS:**
```
1. SORT coins in decreasing order
2. Take LARGEST coin that fits
3. REPEAT until amount becomes 0
```

**ğŸ‘‰ EXAMPLE 1 (Greedy WORKS):**
```
Coins: [1, 5, 10, 25]
Amount: 41

Step 1: Take 25 â†’ Remaining: 16
Step 2: Take 10 â†’ Remaining: 6
Step 3: Take 5 â†’ Remaining: 1
Step 4: Take 1 â†’ Remaining: 0

Answer: 4 coins (25+10+5+1) âœ“ OPTIMAL
```

**ğŸ‘‰ EXAMPLE 2 (Greedy FAILS!):**
```
Coins: [1, 3, 4]
Amount: 6

Greedy approach:
Take 4 â†’ Remaining: 2
Take 1 â†’ Remaining: 1
Take 1 â†’ Remaining: 0
Result: 3 coins (4+1+1) âœ—

OPTIMAL approach:
Take 3 â†’ Remaining: 3
Take 3 â†’ Remaining: 0
Result: 2 coins (3+3) âœ“ BETTER!
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n log n) for sorting + O(amount/smallest_coin)
- **Space**: O(1)

**âš ï¸ CRITICAL FOR EXAM:**
**When Greedy WORKS:**
- Standard currency: {1, 5, 10, 25, 50, 100} âœ“
- Each coin divides the next: {1, 2, 4, 8} âœ“

**When Greedy FAILS:**
- Arbitrary denominations like {1, 3, 4} âœ—
- **USE DYNAMIC PROGRAMMING instead!**

**âœï¸ FOR THEORY EXAM WRITE:**
- "Greedy: **largest coin first**"
- "Not always optimal - depends on coin system"
- "For arbitrary coins, use **DP approach**"
- "Know examples where greedy fails!"

---

## ğŸ”¤ **STRING ALGORITHMS** â­â­â­â­

**ğŸ“– WHAT ARE STRING ALGORITHMS?**
Algorithms for searching patterns in text efficiently.

### 1. RABIN-KARP (Pattern Matching with Hashing)

**ğŸ“– WHAT IS IT?**
Finds a pattern in text using a **rolling hash** function - like a sliding window with fingerprints!

**ğŸ¯ WHY USE IT?**
- Searching in documents (Ctrl+F)
- Plagiarism detection
- Finding multiple patterns at once

**ğŸ“ DEFINITION FOR EXAM:**
"Rabin-Karp uses hashing to find pattern matches in text. It computes hash values for pattern and text windows, using a rolling hash to slide efficiently through the text."

**ğŸ”¢ HOW IT WORKS:**
```
1. Calculate HASH of pattern
2. Calculate HASH of first window in text
3. COMPARE hashes:
   - If match â†’ verify character by character
   - If no match â†’ slide window
4. Use ROLLING HASH to update window hash efficiently
5. REPEAT until end of text
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Text: "HELLO WORLD"
Pattern: "WORLD"

Imagine hash as sum of ASCII values (simplified):

Pattern "WORLD" hash = (some value X)

Slide through text:
Window 1: "HELLO" â†’ hash â‰  X
Window 2: "ELLO " â†’ hash â‰  X
Window 3: "LLO W" â†’ hash â‰  X
...
Window 7: "WORLD" â†’ hash = X âœ“ MATCH!
         â†’ Verify: W=W, O=O, R=R, L=L, D=D âœ“

Pattern found at position 6!
```

**â±ï¸ COMPLEXITY:**
- **Average**: O(n+m) - Very good!
- **Worst case**: O(nm) - when many hash collisions
- n = text length, m = pattern length

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **rolling hash function**"
- "Fast average case: O(n+m)"
- "Good for **multiple pattern** search"
- "Hash collision needs character verification"

---

### 2. KMP (Knuth-Morris-Pratt Algorithm)

**ğŸ“– WHAT IS IT?**
Smart pattern matching that **never backtracks** in the text - it "remembers" what it already matched!

**ğŸ¯ WHY USE IT?**
- Faster than naive search
- Good when pattern has repeating characters
- Used in text editors

**ğŸ“ DEFINITION FOR EXAM:**
"KMP algorithm uses a Longest Prefix Suffix (LPS) array to avoid re-checking already matched characters, achieving O(n+m) time complexity."

**ğŸ”¢ HOW IT WORKS:**
```
STEP 1: Build LPS array (preprocessing)
        LPS tells: when mismatch occurs, where to continue

STEP 2: Search using LPS
        - Match characters
        - On mismatch, use LPS to skip unnecessary comparisons
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Pattern: "ABABC"

STEP 1: Build LPS array
A B A B C
0 0 1 2 0

Why? 
- A: no prefix/suffix â†’ 0
- AB: no match â†’ 0
- ABA: "A" matches â†’ 1
- ABAB: "AB" matches â†’ 2
- ABABC: no match â†’ 0

STEP 2: Search in text
Text: "ABABDABACDABABCABAB"
           â†‘ mismatch at D
Instead of starting over, LPS says:
"You already matched AB, continue from there!"

Positions found: 10
```

**ğŸ‘‰ SIMPLER VISUALIZATION:**
```
Normal search: ABABC
Text:         ABABDABABC...
              âœ“âœ“âœ“âœ“âœ—
              Start again from B? NO!
              
KMP:          Already know first 2 matched
              Jump smartly using LPS!
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n+m) - guaranteed!
- **Space**: O(m) - for LPS array

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **LPS (Longest Prefix Suffix)** array"
- "Never backtracks in text - efficient!"
- "Preprocessing: O(m), Search: O(n)"
- "Best for patterns with repeated characters"

---

### 3. MANACHER'S ALGORITHM (Longest Palindrome)

**ğŸ“– WHAT IS IT?**
Finds the longest palindromic substring in **linear time** - amazingly fast!

**ğŸ¯ WHY USE IT?**
- Finding palindromes in DNA sequences
- Text analysis
- Competitive programming

**ğŸ“ DEFINITION FOR EXAM:**
"Manacher's algorithm finds the longest palindromic substring in O(n) time by cleverly using previously computed palindrome information to avoid redundant checks."

**ğŸ”¢ WHAT IS A PALINDROME?**
Reads same forwards and backwards:
- "racecar" âœ“
- "madam" âœ“
- "noon" âœ“
- "hello" âœ—

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
String: "babad"

Check all substrings for palindrome:
"b" â†’ palindrome âœ“
"ba" â†’ not palindrome
"bab" â†’ palindrome âœ“ (3 chars)
"baba" â†’ not palindrome
"babad" â†’ not palindrome
"a" â†’ palindrome âœ“
"aba" â†’ palindrome âœ“ (3 chars)
"abad" â†’ not palindrome
...

Longest palindromes: "bab" or "aba" (length = 3)
```

**â±ï¸ COMPLEXITY:**
- **Naive approach**: O(nÂ³) - check all substrings
- **Better approach**: O(nÂ²) - expand around centers
- **Manacher's**: O(n) - uses smart mirroring!

**ğŸ”‘ KEY CONCEPT:**
Manacher's uses the idea that palindromes **mirror** around center:
```
If "abcba" is palindrome:
     â†“ center
   a b c b a
   â†‘       â†‘
   mirror!
```

**âœï¸ FOR THEORY EXAM WRITE:**
- "Finds longest palindrome in **O(n) time**"
- "Uses concept of **palindrome mirroring**"
- "Processes both odd & even length palindromes"
- "Much faster than naive O(nÂ³) approach"
- "Uses preprocessing to avoid redundant checks"

---
- Never backtracks in text
- Time: O(n+m)
- Space: O(m)

Example:
pattern = "AABAACAABAA"
LPS = [0,1,0,1,2,0,1,2,3,4,5]
```

### 3. MANACHER'S ALGORITHM (Longest Palindrome)
```
MANACHER(s):
    // Transform: "aba" â†’ "#a#b#a#"
    T = "#"
    for char in s:
        T += char + "#"
    
    n = T.length
    P = [0] * n  // Palindrome radius
    center = 0
    right = 0
    
    for i = 0 to n-1:
        mirror = 2 * center - i
        
        if i < right:
            P[i] = min(right - i, P[mirror])
        
        // Expand around center
        while i + P[i] + 1 < n and i - P[i] - 1 >= 0:
            if T[i + P[i] + 1] == T[i - P[i] - 1]:
                P[i]++
            else:
                break
        
        // Update center and right
        if i + P[i] > right:
            center = i
            right = i + P[i]
    
    // Find max palindrome
    maxLen = max(P)
    centerIndex = P.index(maxLen)
    start = (centerIndex - maxLen) / 2
    
    return s[start...start+maxLen-1]

Key Points:
- Finds longest palindrome in O(n)
- Transform string to handle even/odd lengths
- Reuses previously computed information
- Space: O(n)

Example:
s = "babad"
T = "#b#a#b#a#d#"
Result: "bab" or "aba"
```

---

## ğŸ”„ **BACKTRACKING** â­â­â­â­

**ğŸ“– WHAT IS BACKTRACKING?**
Backtracking means **trying all possibilities** and going back (backtracking) when you hit a dead end.

**Think of it like:** Solving a maze - try path, if blocked, go back and try another!

### 1. GRAPH COLORING (M-Coloring Problem)

**ğŸ“– WHAT IS IT?**
Color a graph with M colors such that no two adjacent (connected) vertices have the same color.

**ğŸ¯ REAL-WORLD USE:**
- Map coloring (countries on map)
- Time table scheduling (no conflicts)
- Register allocation in compilers

**ğŸ“ DEFINITION FOR EXAM:**
"Graph Coloring assigns colors to vertices such that no adjacent vertices share the same color, using backtracking to try all color combinations."

**ğŸ”¢ HOW IT WORKS:**
```
1. Start with first vertex
2. Try COLOR 1:
   - If safe (no neighbor has this color) â†’ assign it
   - Move to next vertex
3. If stuck (no color works):
   - BACKTRACK â†’ change previous vertex's color
4. Repeat until all vertices colored
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Graph: Triangle (3 vertices, all connected)
      1
     /  \
    2----3

Colors available: Red, Blue, Green

Step 1: Color vertex 1 â†’ RED
Step 2: Color vertex 2 â†’ BLUE (can't be RED, neighbor!)
Step 3: Color vertex 3 â†’ GREEN (can't be RED or BLUE!)

Result: [RED, BLUE, GREEN] âœ“

Minimum colors needed: 3
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(m^n) - try m colors for n vertices
- **Space**: O(n) - recursion stack

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **backtracking** - try and revert"
- "Check safety: no adjacent same color"
- "Applications: scheduling, map coloring"
- "Chromatic number = minimum colors needed"

---

### 2. N-QUEENS PROBLEM

**ğŸ“– WHAT IS IT?**
Place N queens on NÃ—N chessboard so that no queen attacks another.

**ğŸ¯ RULES:**
Queens can attack:
- Same ROW â†”
- Same COLUMN â†•
- Same DIAGONAL â†—â†˜

**ğŸ“ DEFINITION FOR EXAM:**
"N-Queens places N queens on NÃ—N board using backtracking such that no two queens threaten each other (no shared row, column, or diagonal)."

**ğŸ”¢ HOW IT WORKS:**
```
1. Place queen in ROW 0, try each column
2. Move to ROW 1, find safe column
3. If no safe column in current row:
   - BACKTRACK to previous row
   - Try next position
4. Continue until all N queens placed
```

**ğŸ‘‰ SIMPLE EXAMPLE (4-Queens):**
```
4Ã—4 Board:

Try placing queens:

Row 0: Place at column 1
. Q . .    â† Queen 1

Row 1: Can't use col 0,1,2 (attacked)
. . . Q    â† Queen 2

Row 2: Try col 0
Q . . .    â† SAFE? Check...
   
If stuck, BACKTRACK!

Final solution:
. Q . .    Row 0
. . . Q    Row 1
Q . . .    Row 2
. . Q .    Row 3

No queen attacks another! âœ“
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(N!) - factorial
- **Space**: O(N) - recursion

**âœï¸ FOR THEORY EXAM WRITE:**
- "Classic **backtracking** problem"
- "Check row, column, and **both diagonals**"
- "Place row by row"
- "Time complexity: O(N!)"

---

### 3. SUDOKU SOLVER

**ğŸ“– WHAT IS IT?**
Fill 9Ã—9 grid with digits 1-9 following Sudoku rules.

**ğŸ¯ SUDOKU RULES:**
Each digit 1-9 must appear:
- Once in each ROW
- Once in each COLUMN
- Once in each 3Ã—3 BOX

**ğŸ“ DEFINITION FOR EXAM:**
"Sudoku Solver uses backtracking to fill empty cells with digits 1-9, checking row, column, and 3Ã—3 box constraints."

**ğŸ”¢ HOW IT WORKS:**
```
1. Find empty cell
2. Try digits 1 to 9:
   - Check if VALID (row, column, box)
   - If valid â†’ place it, move to next cell
3. If no digit works:
   - BACKTRACK â†’ remove last placed digit
   - Try next digit
4. Repeat until board complete
```

**ğŸ‘‰ SIMPLE EXAMPLE (4Ã—4 mini-Sudoku):**
```
Rules: 1-4 in each row, column, and 2Ã—2 box

Initial:
. 2 | 3 .
4 . | . 1
----+----
. 4 | 1 .
3 . | . 4

Solve:
Step 1: Top-left must be 1 (only option)
Step 2: Continue filling...

Final:
1 2 | 3 4
4 3 | 2 1
----+----
2 4 | 1 3
3 1 | 4 2  âœ“
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(9^m) where m = empty cells
- **Space**: O(1) if modifying in-place

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **backtracking** with constraint checking"
- "Checks: row, column, and 3Ã—3 sub-grid"
- "Fills cells one by one"
- "Backtracks when no valid number"

---

## ğŸ’ **DYNAMIC PROGRAMMING (DP)** â­â­â­â­â­

**ğŸ“– WHAT IS DYNAMIC PROGRAMMING?**
DP solves complex problems by **breaking them into smaller overlapping subproblems** and **storing results** to avoid recomputing!

**Think of it like:** Writing answers in your notebook so you don't solve same problem twice!

**ğŸ”‘ TWO KEY PROPERTIES:**
1. **Overlapping Subproblems** - same smaller problems appear multiple times
2. **Optimal Substructure** - optimal solution uses optimal solutions of subproblems

### 1. KNAPSACK (0/1) - Cannot Break Items

**ğŸ“– WHAT IS IT?**
Fill a bag with items to maximize value, but you can only take FULL items (can't break them).

**ğŸ¯ REAL-WORLD USE:**
- Loading cargo (full boxes only)
- Investment decisions (buy whole stocks)
- Resource allocation

**ğŸ“ DEFINITION FOR EXAM:**
"0/1 Knapsack uses Dynamic Programming to find maximum value that can fit in weight capacity W, where each item can be taken (1) or left (0)."

**ğŸ”¢ HOW IT WORKS:**
```
Build a TABLE (2D array):
Rows = items
Columns = weights from 0 to W

For each cell:
  If item weight â‰¤ current capacity:
    CHOOSE MAX of:
      - Take item: item_value + dp[previous items][remaining weight]
      - Skip item: dp[previous items][same weight]
  Else:
    Skip item (too heavy)
```

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Items:
Item 1: weight=2kg, value=â‚¹6
Item 2: weight=3kg, value=â‚¹10
Item 3: weight=4kg, value=â‚¹12

Bag capacity: 5kg

DP Table:
       Weightâ†’  0  1  2  3  4  5
Item â†“
0 (none)        0  0  0  0  0  0
1 (2kg,â‚¹6)      0  0  6  6  6  6
2 (3kg,â‚¹10)     0  0  6 10 10 16
3 (4kg,â‚¹12)     0  0  6 10 12 16

Answer: â‚¹16 (take items 1 and 2)
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(n Ã— W) where n=items, W=capacity
- **Space**: O(n Ã— W), can optimize to O(W)

**âš ï¸ CRITICAL:**
- **0/1 Knapsack**: Cannot break items â†’ Use DP!
- **Fractional Knapsack**: Can break items â†’ Use Greedy!

**âœï¸ FOR THEORY EXAM WRITE:**
- "Uses **DP table** - rows=items, cols=weights"
- "Choice: include or exclude each item"
- "Time: O(nÃ—W), Space: O(nÃ—W)"
- "Different from fractional (greedy fails here!)"

---

### 2. COIN CHANGE PROBLEM (DP Approach)

**ğŸ“– WHAT IS IT?**
Make change for amount using minimum coins OR count total ways to make change.

**ğŸ“ TWO VERSIONS:**

**A) MINIMUM COINS NEEDED:**

**Definition:** "Find minimum number of coins needed to make amount, using DP to try all combinations."

**ğŸ‘‰ EXAMPLE:**
```
Coins: [1, 5, 10]
Amount: 14

DP approach:
Amount 0: 0 coins â† BASE
Amount 1: 1 coin (1)
Amount 2: 2 coins (1+1)
...
Amount 10: 1 coin (10)
Amount 11: 2 coins (10+1)
Amount 14: 2 coins (10+1+1+1+1) NO!
         = 5 coins? NO!
         = Optimal: 5+5+1+1+1+1 = 6 coins? NO!
         = Best: 10+1+1+1+1 = 5 coins

Actually: 14 = 10+1+1+1+1 = 5 coins
Better: No! That's wrong too!

CORRECT: 14 = 10 + 1 + 1 + 1 + 1 (5 coins)
NO WAIT: Can't we do better?
14 = 5 + 5 + 1 + 1 + 1 + 1 (6 coins)

ACTUALLY BEST: Let me recalculate:
14 with [1,5,10]
Try: 10 + ? â†’ need 4 more â†’ 1+1+1+1 = 4 ones
Total: 1+4 = 5 coins âœ“ (10,1,1,1,1)
```

**B) COUNT NUMBER OF WAYS:**

**ğŸ‘‰ EXAMPLE:**
```
Coins: [1, 2, 3]
Amount: 4

Ways:
1. 1+1+1+1 (4 ones)
2. 1+1+2 (two ones, one two)
3. 2+2 (two twos)
4. 1+3 (one one, one three)

Total: 4 ways
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(amount Ã— number of coins)
- **Space**: O(amount)

**âœï¸ FOR THEORY EXAM WRITE:**
- "Use DP when coin set is **arbitrary** (greedy fails!)"
- "Min coins: dp[i] = min(dp[i], 1 + dp[i-coin])"
- "Count ways: iterate coins first to avoid duplicates"
- "Example where greedy fails: coins=[1,3,4], amount=6"

---

### 3. LCS (Longest Common Subsequence)

**ğŸ“– WHAT IS IT?**
Find longest sequence that appears in same order in both strings (but not necessarily consecutive).

**ğŸ¯ DIFFERENCE:**
- **Subsequence**: Can skip characters â†’ "ace" from "abcde"
- **Substring**: Must be consecutive â†’ "abc" from "abcde"

**ğŸ“ DEFINITION FOR EXAM:**
"LCS finds the longest subsequence common to two sequences using DP, where characters appear in same order but need not be consecutive."

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
String X: "ABCDGH"
String Y: "AEDFHR"

Find matches:
A - A âœ“
B - (skip)
C - (skip)
D - D âœ“
(skip E, F)
H - H âœ“

LCS: "ADH" (length = 3)
```

**ğŸ”¢ HOW IT WORKS:**
```
Build DP table:

If characters match:
  dp[i][j] = 1 + dp[i-1][j-1]
  
If don't match:
  dp[i][j] = max(dp[i-1][j], dp[i][j-1])
```

**DP TABLE VISUALIZATION:**
```
       ""  A  E  D  F  H  R
    "" 0   0  0  0  0  0  0
    A  0   1  1  1  1  1  1
    B  0   1  1  1  1  1  1
    C  0   1  1  1  1  1  1
    D  0   1  1  2  2  2  2
    G  0   1  1  2  2  2  2
    H  0   1  1  2  2  3  3

Answer: dp[6][6] = 3 âœ“
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(m Ã— n) where m, n are string lengths
- **Space**: O(m Ã— n)

**âœï¸ FOR THEORY EXAM WRITE:**
- "**Subsequence** not substring!"
- "DP table: match â†’ diagonal+1, no match â†’ max(top,left)"
- "Applications: diff tools, DNA comparison"
- "Can reconstruct actual LCS by backtracking table"

---

Example:
X = "ABCDGH", Y = "AEDFHR"
LCS = 3 (ADH)
```

### 4. LIS (Longest Increasing Subsequence)

**ğŸ“– WHAT IS IT?**
Find longest subsequence where numbers are in **increasing order**.

**ğŸ“ DEFINITION FOR EXAM:**
"LIS finds the longest subsequence from an array where elements are in strictly increasing order, using DP to check all possibilities."

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Array: [10, 9, 2, 5, 3, 7, 101, 18]

Find increasing subsequences:
[10] - length 1
[10, 101] - length 2
[2, 5, 7, 101] - length 4 âœ“
[2, 3, 7, 18] - length 4 âœ“
[2, 5, 7, 18] - length 4 âœ“

Longest Length: 4
```

**ğŸ”¢ HOW IT WORKS:**
```
For each position i:
  dp[i] = longest increasing sequence ending at i
  
Check all previous positions j < i:
  If arr[j] < arr[i]:
    dp[i] = max(dp[i], dp[j] + 1)
```

**â±ï¸ COMPLEXITY:**
- **Basic DP**: O(nÂ²) - easy to understand
- **Optimized**: O(n log n) - uses binary search

**âœï¸ FOR THEORY EXAM WRITE:**
- "dp[i] = LIS ending at index i"
- "Check all previous smaller elements"
- "Time: O(nÂ²) or O(n log n) optimized"
- "Different from LCS!"

---

### 5. LPS (Longest Palindromic Subsequence)

**ğŸ“– WHAT IS IT?**
Find longest palindrome that can be formed using subsequence (not necessarily consecutive).

**ğŸ“ DEFINITION FOR EXAM:**
"LPS finds the longest palindromic subsequence in a string, where characters can be non-consecutive but must maintain relative order."

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
String: "BBABCBCAB"

Palindromic subsequences:
"BB" - length 2
"BAB" - length 3
"BABAB" - length 5
"BABCBAB" - length 7 âœ“ LONGEST!

Answer: 7
```

**ğŸ”¢ HOW IT WORKS:**
```
If first and last characters match:
  LPS = 2 + LPS(middle part)
  
If they don't match:
  LPS = max(
    LPS(skip first),
    LPS(skip last)
  )
```

**ğŸ’¡ TRICK:**
Can also solve by:
**LPS(s) = LCS(s, reverse(s))**

```
Example:
s = "BBABCBCAB"
reverse = "BACBCBABB"

Find LCS â†’ gives LPS!
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(nÂ²)
- **Space**: O(nÂ²)

**âœï¸ FOR THEORY EXAM WRITE:**
- "**Interval DP** problem"
- "Can use LCS with reversed string"
- "Match ends â†’ include both + recurse middle"
- "No match â†’ max of (skip left, skip right)"

---

### 6. MINIMUM PATH SUM (Grid/Matrix)

**ğŸ“– WHAT IS IT?**
Find path from top-left to bottom-right in grid with minimum sum. Can only move right or down.

**ğŸ“ DEFINITION FOR EXAM:**
"Minimum Path Sum finds the path from top-left to bottom-right corner with minimum sum, allowing only right and down movements, using DP."

**ğŸ‘‰ SIMPLE EXAMPLE:**
```
Grid:
1  3  1
1  5  1
4  2  1

Possible paths:
Path 1: 1â†’3â†’1â†’1â†’1 = 7 âœ“ MINIMUM
Path 2: 1â†’1â†’5â†’1â†’1 = 9
Path 3: 1â†’1â†’4â†’2â†’1 = 9

Answer: 7
```

**ğŸ”¢ HOW IT WORKS:**
```
Build DP table:

For each cell:
  dp[i][j] = grid[i][j] + min(
    dp[i-1][j],  â† from top
    dp[i][j-1]   â† from left
  )

First row: can only come from left
First column: can only come from top
```

**DP TABLE:**
```
Grid:          DP Table:
1  3  1        1  4  5
1  5  1   â†’    2  7  6
4  2  1        6  8  7

Answer: dp[2][2] = 7
```

**â±ï¸ COMPLEXITY:**
- **Time**: O(m Ã— n)
- **Space**: O(m Ã— n), can optimize to O(n)

**âœï¸ FOR THEORY EXAM WRITE:**
- "Only **right** and **down** moves allowed"
- "dp[i][j] = grid[i][j] + min(top, left)"
- "Initialize first row and column separately"
- "Similar to: Unique Paths problem"

---

---

## ğŸš¨ EXAM STRATEGY FOR THESE TOPICS

### For GRAPH:
âœ… **Kruskal**: Always mention Union-Find and "sort edges by weight"
âœ… **Dijkstra**: State "non-negative weights only" requirement  
âœ… Draw small graph example to show understanding

### For RECURSION:
âœ… **Always write base case FIRST** - this is critical!
âœ… Show recurrence relation: T(n) = ...  
âœ… State time complexity with reason (exponential/linear)

### For GREEDY:
âœ… **Prove greedy choice works** (or state when it fails!)
âœ… Show sorting step clearly  
âœ… Know examples where greedy fails (coin change!)

### For STRINGS:
âœ… **KMP**: Explain LPS array purpose
âœ… **Rabin-Karp**: Mention rolling hash benefit
âœ… **Manacher's**: State O(n) achievement

### For BACKTRACKING:
âœ… **Three steps**: Try â†’ Recurse â†’ Backtrack  
âœ… Explain what "backtrack" means (undo and try next)
âœ… State exponential time complexity

### For DP:
âœ… **Define state clearly**: "dp[i][j] represents..."  
âœ… Write recurrence relation  
âœ… Explain base cases
âœ… State overlapping subproblems + optimal substructure

---

## ğŸ“‹ QUICK REFERENCE CHEAT SHEET

### TIME COMPLEXITIES (Know These!)
| Algorithm | Time Complexity | Space |
|-----------|----------------|--------|
| **Kruskal** | O(E log E) | O(V) |
| **Dijkstra** | O((V+E) log V) | O(V) |
| **Fibonacci (naive)** | O(2^n) | O(n) |
| **Fibonacci (DP)** | O(n) | O(n) |
| **Tower of Hanoi** | O(2^n) | O(n) |
| **Activity Selection** | O(n log n) | O(1) |
| **Fractional Knapsack** | O(n log n) | O(1) |
| **Rabin-Karp** | O(n+m) avg | O(1) |
| **KMP** | O(n+m) | O(m) |
| **Manacher's** | O(n) | O(n) |
| **N-Queens** | O(N!) | O(N) |
| **0/1 Knapsack** | O(nÃ—W) | O(nÃ—W) |
| **Coin Change** | O(amountÃ—coins) | O(amount) |
| **LCS** | O(mÃ—n) | O(mÃ—n) |
| **LIS** | O(nÂ²) or O(n log n) | O(n) |
| **Min Path Sum** | O(mÃ—n) | O(mÃ—n) |

### KEY CONCEPTS TO REMEMBER

**GREEDY vs DP:**
- Greedy: Local best choice â†’ May not be globally optimal
- DP: Try all possibilities â†’ Guaranteed optimal

**When Greedy WORKS:**
- Activity Selection âœ“
- Fractional Knapsack âœ“
- Kruskal's MST âœ“
- Dijkstra (non-negative weights) âœ“

**When Greedy FAILS (use DP):**
- 0/1 Knapsack âœ—
- Arbitrary Coin Change âœ—

**RECURSION KEY:**
- **Base case** = stopping condition
- **Recurrence** = problem in terms of smaller problem
- Always write base case first!

**DP PATTERNS:**
- **Linear DP**: Fibonacci, Coin Change, LIS
- **2D DP**: Knapsack, LCS, Grid problems
- **Interval DP**: LPS

**BACKTRACKING PATTERN:**
```
1. Make a choice
2. Recurse
3. If solution found â†’ return
4. Else â†’ Undo choice (backtrack)
5. Try next choice
```

---

## â° TONIGHT'S STUDY PLAN (7 HOURS)

### ğŸ• Hour 1-2: DYNAMIC PROGRAMMING (Most Important!)
**Why:** Maximum problems in exam from here!
- Focus: 0/1 Knapsack, Coin Change, LCS
- Practice: Draw DP table for small example
- Understand: Include/exclude pattern

### ğŸ•’ Hour 3: GRAPH ALGORITHMS
**Why:** Teacher specifically emphasized!
- Kruskal: Remember Union-Find
- Dijkstra: Remember non-negative weights limitation
- Draw one example of each

### ğŸ•“ Hour 4: RECURSION (All 6 problems)
**Why:** Foundation for many algorithms!
- Fibonacci, Factorial (easy ones first)
- Tower of Hanoi, GCD (medium)
- Practice writing base cases

### ğŸ•” Hour 5: GREEDY + STRINGS
- Greedy: Know when it fails!
- Activity Selection pattern
- KMP: Understand LPS concept
- Rabin-Karp: Rolling hash idea

### ğŸ•• Hour 6: BACKTRACKING
- N-Queens: Understand row-by-row approach
- Graph Coloring: Safety check concept
- General backtracking pattern

### ğŸ•– Hour 7: REVISION & PRACTICE
- Read all definitions again
- Practice explaining 2-3 algorithms aloud
- Review this cheat sheet
- Check complexity table

### ğŸ›Œ SLEEP! (Critical!)
Get 6-7 hours sleep - your brain needs it to consolidate!

---

## ğŸ¯ FINAL EXAM TIPS

### Writing Answers:
1. **Start with definition** - 2-3 lines
2. **Explain purpose** - Real-world use
3. **Show steps** - Numbered list
4. **Give example** - Small, clear example
5. **State complexity** - Time and space

### Time Management:
- **Graphs**: 15 minutes each
- **Recursion**: 8-10 minutes each
- **DP**: 15 minutes each
- **Others**: 10 minutes each

### Common Mistakes to Avoid:
âŒ Forgetting to state base case in recursion
âŒ Confusing subsequence with substring
âŒ Not mentioning time complexity
âŒ Using greedy when DP is needed
âŒ Forgetting Dijkstra's limitation (non-negative weights)

### Magic Phrases for Extra Marks:
âœ¨ "This uses **optimal substructure** property..."
âœ¨ "The **greedy choice** property holds because..."
âœ¨ "Time complexity is O(...) due to **nested loops/sorting/recursion depth**..."
âœ¨ "This problem exhibits **overlapping subproblems**..."
âœ¨ "We use **memoization/tabulation** to optimize..."

---

## ğŸ’ª YOU CAN DO THIS!

**Remember:**
- Teacher gave you the priority list - FOCUS on these!
- Understand concepts, don't memorize blindly
- Draw diagrams - they help A LOT
- Examples show you understand
- Sleep is not optional!

**You've got all the material you need. Trust your preparation!** ğŸš€

Good luck with your exam tomorrow! ğŸ“šâœ¨

---

**END OF PRIORITY TOPICS GUIDE**
